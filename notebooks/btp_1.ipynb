{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rg9d_upr6ux"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q dgl torch numpy matplotlib seaborn scikit-learn pandas pymatgen plotly tqdm umap-learn jarvis-tools ase\n",
        "\n",
        "# Mount Google Drive to access your files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import common libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import dgl\n",
        "from dgl.nn import GraphConv, EdgeConv\n",
        "from pymatgen.core.structure import Structure\n",
        "from pymatgen.analysis.local_env import CrystalNN\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set the base directory for your CIF files\n",
        "base_dir = '/content/drive/My Drive/btp_cif'\n",
        "heusler_types = ['full', 'half', 'inverse', 'quaternary']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to handle loading and processing of CIF files\n",
        "class HeuslerCIFDataset:\n",
        "    def __init__(self, base_dir, heusler_types):\n",
        "        self.base_dir = base_dir\n",
        "        self.heusler_types = heusler_types\n",
        "        self.structures = []\n",
        "        self.labels = []\n",
        "        self.formulas = []\n",
        "        self.filenames = []\n",
        "        self.load_structures()\n",
        "\n",
        "    def load_structures(self):\n",
        "        print(\"Loading CIF files...\")\n",
        "        for i, ht in enumerate(self.heusler_types):\n",
        "            folder_path = os.path.join(self.base_dir, ht)\n",
        "            if not os.path.exists(folder_path):\n",
        "                print(f\"Warning: {folder_path} not found, skipping...\")\n",
        "                continue\n",
        "\n",
        "            cif_files = [f for f in os.listdir(folder_path) if f.endswith('.cif')]\n",
        "\n",
        "            for cif_file in tqdm(cif_files, desc=f\"Loading {ht} structures\"):\n",
        "                try:\n",
        "                    file_path = os.path.join(folder_path, cif_file)\n",
        "                    structure = Structure.from_file(file_path)\n",
        "                    self.structures.append(structure)\n",
        "                    self.labels.append(i)  # Use index as label for Heusler type\n",
        "                    self.formulas.append(structure.composition.reduced_formula)\n",
        "                    self.filenames.append(cif_file)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {cif_file}: {e}\")\n",
        "\n",
        "        print(f\"Loaded {len(self.structures)} structures in total\")\n",
        "\n",
        "    def get_structure_info(self):\n",
        "        \"\"\"Extract basic structural information from the loaded CIFs\"\"\"\n",
        "        data = []\n",
        "        for i, structure in enumerate(self.structures):\n",
        "            # Extract basic structural properties\n",
        "            lattice = structure.lattice\n",
        "            volume = lattice.volume\n",
        "            density = structure.density\n",
        "            num_sites = len(structure)\n",
        "            elements = [str(site.specie) for site in structure]\n",
        "            unique_elements = list(set(elements))\n",
        "            num_elements = len(unique_elements)\n",
        "\n",
        "            # Calculate average atomic radius and electronegativity\n",
        "            atomic_radii = [site.specie.atomic_radius for site in structure if site.specie.atomic_radius]\n",
        "            avg_radius = np.mean(atomic_radii) if atomic_radii else np.nan\n",
        "\n",
        "            electronegativities = [site.specie.X for site in structure if site.specie.X]\n",
        "            avg_electronegativity = np.mean(electronegativities) if electronegativities else np.nan\n",
        "\n",
        "            data.append({\n",
        "                'formula': self.formulas[i],\n",
        "                'heusler_type': self.heusler_types[self.labels[i]],\n",
        "                'volume': volume,\n",
        "                'density': density,\n",
        "                'num_sites': num_sites,\n",
        "                'num_elements': num_elements,\n",
        "                'avg_atomic_radius': avg_radius,\n",
        "                'avg_electronegativity': avg_electronegativity,\n",
        "                'filename': self.filenames[i]\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = HeuslerCIFDataset(base_dir, heusler_types)\n",
        "\n",
        "# Get and display structure info\n",
        "structure_info = dataset.get_structure_info()\n",
        "print(\"\\nStructure Info Sample:\")\n",
        "display(structure_info.head())"
      ],
      "metadata": {
        "id": "Tr7g4nipsDKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph construction functions\n",
        "def one_hot_encoding(atomic_number, max_z=94):\n",
        "    \"\"\"Create a one-hot encoding vector for atomic number\"\"\"\n",
        "    encoding = np.zeros(max_z)\n",
        "    if atomic_number <= max_z:\n",
        "        encoding[atomic_number-1] = 1.0\n",
        "    return encoding\n",
        "\n",
        "def build_crystal_graph(structure, cutoff=8.0):\n",
        "    \"\"\"Build atom and bond graphs from pymatgen structure\"\"\"\n",
        "    # Get all sites in structure\n",
        "    all_sites = structure.sites\n",
        "    num_atoms = len(all_sites)\n",
        "\n",
        "    # Initialize arrays for graph construction\n",
        "    src_atoms = []\n",
        "    dst_atoms = []\n",
        "    edge_features = []\n",
        "    atom_features = []\n",
        "\n",
        "    # Build atom features\n",
        "    for i, site in enumerate(all_sites):\n",
        "        # Get atomic properties\n",
        "        atomic_num = site.specie.Z\n",
        "        atomic_feat = one_hot_encoding(atomic_num)\n",
        "\n",
        "        # Add other features like electronegativity, atomic radius\n",
        "        try:\n",
        "            electronegativity = site.specie.X if site.specie.X else 0.0\n",
        "            atomic_radius = site.specie.atomic_radius if site.specie.atomic_radius else 0.0\n",
        "            atomic_mass = site.specie.atomic_mass\n",
        "            # Add these properties to feature vector\n",
        "            additional_feat = np.array([electronegativity, atomic_radius, atomic_mass])\n",
        "            atomic_feat = np.concatenate([atomic_feat, additional_feat])\n",
        "        except:\n",
        "            # If property not available, pad with zeros\n",
        "            atomic_feat = np.concatenate([atomic_feat, np.zeros(3)])\n",
        "\n",
        "        atom_features.append(atomic_feat)\n",
        "\n",
        "    # Get bonds using CrystalNN\n",
        "    cnn = CrystalNN(search_cutoff=cutoff, weighted_cn=True)\n",
        "\n",
        "    # Get bonds\n",
        "    for i, site in enumerate(all_sites):\n",
        "        # Get nearest neighbors\n",
        "        try:\n",
        "            nn_info = cnn.get_nn_info(structure, i)\n",
        "\n",
        "            for neighbor in nn_info:\n",
        "                j = neighbor['site_index']\n",
        "\n",
        "                # Skip self-loops\n",
        "                if i == j:\n",
        "                    continue\n",
        "\n",
        "                # Get bond distance\n",
        "                distance = neighbor['weight']  # Using weight from CrystalNN\n",
        "\n",
        "                # Get displacement vector\n",
        "                center_coords = all_sites[i].coords\n",
        "                neigh_coords = neighbor['site'].coords\n",
        "\n",
        "                # Calculate unit vector of displacement\n",
        "                delta = neigh_coords - center_coords\n",
        "                delta_norm = np.linalg.norm(delta)\n",
        "                if delta_norm > 1e-6:  # Avoid division by zero\n",
        "                    unit_vec = delta / delta_norm\n",
        "                else:\n",
        "                    unit_vec = np.zeros(3)\n",
        "\n",
        "                # Create edge feature\n",
        "                edge_feat = np.concatenate([\n",
        "                    [distance],\n",
        "                    unit_vec,\n",
        "                ])\n",
        "\n",
        "                # Add edges and features\n",
        "                src_atoms.append(i)\n",
        "                dst_atoms.append(j)\n",
        "                edge_features.append(edge_feat)\n",
        "        except Exception as e:\n",
        "            print(f\"Error building graph for site {i}: {e}\")\n",
        "\n",
        "    # Create atom graph\n",
        "    atom_graph = dgl.graph((src_atoms, dst_atoms), num_nodes=num_atoms)\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    atom_features = torch.tensor(np.array(atom_features), dtype=torch.float32)\n",
        "    edge_features = torch.tensor(np.array(edge_features), dtype=torch.float32)\n",
        "\n",
        "    # Create bond graph (line graph of atom graph)\n",
        "    bond_graph = dgl.line_graph(atom_graph, backtracking=False)\n",
        "\n",
        "    # Pad edge features to ensure constant dimension\n",
        "    edge_feat_dim = 4  # distance + 3D unit vector\n",
        "    pad_size = edge_feat_dim - edge_features.shape[1]\n",
        "    if pad_size > 0:\n",
        "        edge_features = torch.cat([edge_features, torch.zeros(edge_features.shape[0], pad_size)], dim=1)\n",
        "\n",
        "    return atom_graph, bond_graph, atom_features, edge_features\n",
        "\n",
        "# Define the ALIGNN model\n",
        "class ALIGNNConv(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, edge_dim):\n",
        "        super().__init__()\n",
        "        self.atom_conv = GraphConv(in_dim, out_dim)\n",
        "        self.bond_conv = EdgeConv(edge_dim, out_dim)\n",
        "        self.update_bond = nn.Sequential(\n",
        "            nn.Linear(out_dim * 2 + edge_dim, out_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(out_dim, out_dim)\n",
        "        )\n",
        "        self.update_atom = nn.Sequential(\n",
        "            nn.Linear(out_dim * 2, out_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(out_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, atom_graph, bond_graph, atom_feat, bond_feat):\n",
        "        # Update atom features using atom graph\n",
        "        new_atom_feat = self.atom_conv(atom_graph, atom_feat)\n",
        "\n",
        "        # Update bond features using bond graph\n",
        "        new_bond_feat = self.bond_conv(bond_graph, bond_feat)\n",
        "\n",
        "        # Update bond features using connected atoms\n",
        "        atom_in = atom_feat[atom_graph.edges()[0]]\n",
        "        atom_out = atom_feat[atom_graph.edges()[1]]\n",
        "        edge_inputs = torch.cat([atom_in, atom_out, bond_feat], dim=1)\n",
        "        bond_feat = bond_feat + self.update_bond(edge_inputs)\n",
        "\n",
        "        # Update atom features using connected bonds\n",
        "        atom_update = torch.zeros_like(atom_feat)\n",
        "        bond_sum = dgl.sum_edges(atom_graph, bond_feat)\n",
        "        atom_update = torch.cat([atom_feat, bond_sum], dim=1)\n",
        "        atom_feat = atom_feat + self.update_atom(atom_update)\n",
        "\n",
        "        return atom_feat, bond_feat\n",
        "\n",
        "class ALIGNN(nn.Module):\n",
        "    def __init__(self, node_feat_dim=97, edge_feat_dim=4, hidden_dim=128, num_layers=4, output_dim=64):\n",
        "        super().__init__()\n",
        "        self.node_embed = nn.Linear(node_feat_dim, hidden_dim)\n",
        "        self.edge_embed = nn.Linear(edge_feat_dim, hidden_dim)\n",
        "\n",
        "        self.alignn_layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.alignn_layers.append(ALIGNNConv(hidden_dim, hidden_dim, hidden_dim))\n",
        "\n",
        "        self.readout = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, atom_graph, bond_graph, atom_feat, bond_feat):\n",
        "        # Initial embedding\n",
        "        atom_feat = self.node_embed(atom_feat)\n",
        "        bond_feat = self.edge_embed(bond_feat)\n",
        "\n",
        "        # Apply ALIGNN layers\n",
        "        for layer in self.alignn_layers:\n",
        "            atom_feat, bond_feat = layer(atom_graph, bond_graph, atom_feat, bond_feat)\n",
        "\n",
        "        # Global pooling\n",
        "        global_feat = dgl.mean_nodes(atom_graph, atom_feat)\n",
        "\n",
        "        # Final readout\n",
        "        output = self.readout(global_feat)\n",
        "\n",
        "        return output, atom_feat, bond_feat"
      ],
      "metadata": {
        "id": "3bmvlWVVsFRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyTorch dataset for the ALIGNN model\n",
        "class ALIGNNHeuslerDataset(Dataset):\n",
        "    def __init__(self, structures):\n",
        "        self.structures = structures\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.structures)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        structure = self.structures[idx]\n",
        "        atom_graph, bond_graph, atom_feat, edge_feat = build_crystal_graph(structure)\n",
        "        return atom_graph, bond_graph, atom_feat, edge_feat\n",
        "\n",
        "# Collate function for batching\n",
        "def collate_fn(batch):\n",
        "    atom_graphs = [item[0] for item in batch]\n",
        "    bond_graphs = [item[1] for item in batch]\n",
        "    atom_feats = [item[2] for item in batch]\n",
        "    edge_feats = [item[3] for item in batch]\n",
        "\n",
        "    batched_atom_graph = dgl.batch(atom_graphs)\n",
        "    batched_bond_graph = dgl.batch(bond_graphs)\n",
        "    batched_atom_feat = torch.cat(atom_feats, dim=0)\n",
        "    batched_edge_feat = torch.cat(edge_feats, dim=0)\n",
        "\n",
        "    return batched_atom_graph, batched_bond_graph, batched_atom_feat, batched_edge_feat"
      ],
      "metadata": {
        "id": "fmRqQfb1sG0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict properties based on structural embeddings\n",
        "def predict_properties(embeddings, structure_info):\n",
        "    \"\"\"Predict properties using k-nearest neighbors in the embedding space\"\"\"\n",
        "\n",
        "    # Properties to predict\n",
        "    properties = ['volume', 'density', 'avg_atomic_radius', 'avg_electronegativity']\n",
        "\n",
        "    # Create a clean dataframe with only numeric columns\n",
        "    clean_df = structure_info[properties].copy()\n",
        "\n",
        "    # Check for and handle missing values\n",
        "    for prop in properties:\n",
        "        if clean_df[prop].isna().any():\n",
        "            print(f\"Warning: {clean_df[prop].isna().sum()} missing values in {prop}\")\n",
        "            # Fill missing values with median\n",
        "            clean_df[prop] = clean_df[prop].fillna(clean_df[prop].median())\n",
        "\n",
        "    # Results dictionary\n",
        "    results = {}\n",
        "\n",
        "    # Prediction for each property\n",
        "    for prop in properties:\n",
        "        print(f\"\\nPredicting {prop} based on structural similarity...\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            embeddings, clean_df[prop], test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Try different k values\n",
        "        k_values = [3, 5, 7, 9]\n",
        "        mae_scores = []\n",
        "        r2_scores = []\n",
        "\n",
        "        for k in k_values:\n",
        "            # Train KNN model\n",
        "            knn = KNeighborsRegressor(n_neighbors=k)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Predict\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "            # Store scores\n",
        "            mae_scores.append(mae)\n",
        "            r2_scores.append(r2)\n",
        "\n",
        "            print(f\"k={k}, MAE={mae:.4f}, R²={r2:.4f}\")\n",
        "\n",
        "        # Find best k\n",
        "        best_k_idx = r2_scores.index(max(r2_scores))\n",
        "        best_k = k_values[best_k_idx]\n",
        "        print(f\"Best k for {prop}: {best_k} (R²={r2_scores[best_k_idx]:.4f})\")\n",
        "\n",
        "        # Train final model with best k\n",
        "        final_model = KNeighborsRegressor(n_neighbors=best_k)\n",
        "        final_model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on test set\n",
        "        y_pred = final_model.predict(X_test)\n",
        "\n",
        "        # Plot actual vs predicted\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
        "        plt.xlabel(f'Actual {prop}')\n",
        "        plt.ylabel(f'Predicted {prop}')\n",
        "        plt.title(f'Actual vs Predicted {prop} (k={best_k}, R²={r2_scores[best_k_idx]:.4f})')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "        # Store results\n",
        "        results[prop] = {\n",
        "            'best_k': best_k,\n",
        "            'mae': mae_scores[best_k_idx],\n",
        "            'r2': r2_scores[best_k_idx],\n",
        "            'model': final_model\n",
        "        }\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\nProperty Prediction Summary:\")\n",
        "    for prop, res in results.items():\n",
        "        print(f\"{prop}: R²={res['r2']:.4f}, MAE={res['mae']:.4f}, best k={res['best_k']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Predict properties\n",
        "print(\"Predicting properties based on structural embeddings...\")\n",
        "property_predictions = predict_properties(embeddings, structure_info)"
      ],
      "metadata": {
        "id": "09Lby7p5sJyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}